{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "easyocr_tflite_report.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minh2210-hq/machine-learning-interview/blob/master/colabs/easyocr_tflite_report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0v8F0d1l9Rk"
      },
      "source": [
        "## SetUp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLhJw2-glxTA"
      },
      "source": [
        "%%bash\n",
        "pip install onnx\n",
        "pip install onnxruntime\n",
        "pip install git+https://github.com/onnx/onnx-tensorflow.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KS0FaBPgnPFA"
      },
      "source": [
        "import torch\n",
        "import onnx\n",
        "import onnxruntime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from onnx_tf.backend import prepare"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stoSSjo-mnkc"
      },
      "source": [
        "## Download converted ONNX model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFviZPClmBDD"
      },
      "source": [
        "%%bash\n",
        "wget https://github.com/tulasiram58827/ocr_tflite/raw/main/models/easyocr_onnx/sequence_modeller.onnx\n",
        "wget https://raw.githubusercontent.com/tulasiram58827/ocr_tflite/main/data/en.txt\n",
        "wget https://github.com/tulasiram58827/ocr_tflite/raw/main/data/feature_extracted.pt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7CRnb0rnoua"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6zIRwI7rXz_"
      },
      "source": [
        "The below code is also part of [EasyOCR](https://github.com/JaidedAI/EasyOCR) repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZ1IDjh7nrbN"
      },
      "source": [
        "dict_list = {}\n",
        "dict_list['en'] = '/content/en.txt'\n",
        "number = '0123456789'\n",
        "symbol  = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ '\n",
        "chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyzÀÁÂÃÄÅÆÇÈÉÊËÍÎÑÒÓÔÕÖØÚÛÜÝÞßàáâãäåæçèéêëìíîïðñòóôõöøùúûüýþÿąęĮįıŁłŒœŠšųŽž'\n",
        "characters = number+ symbol + chars"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p30CITtwobVa"
      },
      "source": [
        "class CTCLabelConverter(object):\n",
        "    \"\"\" Convert between text-label and text-index \"\"\"\n",
        "\n",
        "    def __init__(self, character, separator_list = {}, dict_pathlist = {}):\n",
        "        # character (str): set of the possible characters.\n",
        "        dict_character = list(character)\n",
        "\n",
        "        self.dict = {}\n",
        "        for i, char in enumerate(dict_character):\n",
        "            self.dict[char] = i + 1\n",
        "\n",
        "        self.character = ['[blank]'] + dict_character  # dummy '[blank]' token for CTCLoss (index 0)\n",
        "\n",
        "        self.separator_list = separator_list\n",
        "        separator_char = []\n",
        "        for lang, sep in separator_list.items():\n",
        "            separator_char += sep\n",
        "        self.ignore_idx = [0] + [i+1 for i,item in enumerate(separator_char)]\n",
        "\n",
        "        ####### latin dict\n",
        "        if len(separator_list) == 0:\n",
        "            dict_list = []\n",
        "            for lang, dict_path in dict_pathlist.items():\n",
        "                try:\n",
        "                    with open(dict_path, \"r\", encoding = \"utf-8-sig\") as input_file:\n",
        "                        word_count =  input_file.read().splitlines()\n",
        "                    dict_list += word_count\n",
        "                except:\n",
        "                    pass\n",
        "        else:\n",
        "            dict_list = {}\n",
        "            for lang, dict_path in dict_pathlist.items():\n",
        "                with open(dict_path, \"r\", encoding = \"utf-8-sig\") as input_file:\n",
        "                    word_count =  input_file.read().splitlines()\n",
        "                dict_list[lang] = word_count\n",
        "\n",
        "        self.dict_list = dict_list\n",
        "\n",
        "    def encode(self, text, batch_max_length=25):\n",
        "        \"\"\"convert text-label into text-index.\n",
        "        input:\n",
        "            text: text labels of each image. [batch_size]\n",
        "        output:\n",
        "            text: concatenated text index for CTCLoss.\n",
        "                    [sum(text_lengths)] = [text_index_0 + text_index_1 + ... + text_index_(n - 1)]\n",
        "            length: length of each text. [batch_size]\n",
        "        \"\"\"\n",
        "        length = [len(s) for s in text]\n",
        "        text = ''.join(text)\n",
        "        text = [self.dict[char] for char in text]\n",
        "\n",
        "        return (torch.IntTensor(text), torch.IntTensor(length))\n",
        "\n",
        "    def decode_greedy(self, text_index, length):\n",
        "        \"\"\" convert text-index into text-label. \"\"\"\n",
        "        texts = []\n",
        "        index = 0\n",
        "        for l in length:\n",
        "            t = text_index[index:index + l]\n",
        "\n",
        "            char_list = []\n",
        "            for i in range(l):\n",
        "                # removing repeated characters and blank (and separator).\n",
        "                if t[i] not in self.ignore_idx and (not (i > 0 and t[i - 1] == t[i])):\n",
        "                    char_list.append(self.character[t[i]])\n",
        "            text = ''.join(char_list)\n",
        "\n",
        "            texts.append(text)\n",
        "            index += l\n",
        "        return texts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH40pK91nve0"
      },
      "source": [
        "def post_process(preds, character, separator_list, dict_list, batch_size=1):\n",
        "    result = []\n",
        "    ignore_idx = []\n",
        "    converter = CTCLabelConverter(character, separator_list, dict_list)\n",
        "    preds_size = torch.IntTensor([preds.size(1)] * batch_size)\n",
        "    ######## filter ignore_char, rebalance\n",
        "    preds_prob = F.softmax(preds, dim=2)\n",
        "    preds_prob = preds_prob.cpu().detach().numpy()\n",
        "    preds_prob[:,:,ignore_idx] = 0.\n",
        "    pred_norm = preds_prob.sum(axis=2)\n",
        "    preds_prob = preds_prob/np.expand_dims(pred_norm, axis=-1)\n",
        "    preds_prob = torch.from_numpy(preds_prob).float().to('cpu')\n",
        "    # if decoder == 'greedy':\n",
        "    # Select max probabilty (greedy decoding) then decode index to character\n",
        "    _, preds_index = preds_prob.max(2)\n",
        "    preds_index = preds_index.view(-1)\n",
        "    preds_str = converter.decode_greedy(preds_index.data, preds_size.data)\n",
        "    preds_max_prob, _ = preds_prob.max(dim=2)\n",
        "    for pred, pred_max_prob in zip(preds_str, preds_max_prob):\n",
        "        confidence_score = pred_max_prob.cumprod(dim=0)[-1]\n",
        "        result.append([pred, confidence_score.item()])\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WitgICWm0HG"
      },
      "source": [
        "## ONNX Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVbLhNmRmtK_"
      },
      "source": [
        "def to_numpy(tensor):\n",
        "    return tensor.detach().cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goC0Gm-2m17v"
      },
      "source": [
        "data = torch.load('/content/feature_extracted.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dj_AVeOanTkE",
        "outputId": "70e40761-7dc2-41e4-97c9-70dcc9238a2c"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 41, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0nF96r3nWef",
        "outputId": "33681e7d-5f8c-4761-b5a9-d89f01b2557f"
      },
      "source": [
        "# Load sequence modeller of ONNX model\n",
        "onnx_model = onnx.load(\"sequence_modeller.onnx\")\n",
        "# Check the model\n",
        "onnx.checker.check_model(onnx_model)\n",
        "ort_session = onnxruntime.InferenceSession(\"sequence_modeller.onnx\")\n",
        "\n",
        "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(data)}\n",
        "ort_outs = ort_session.run(None, ort_inputs)\n",
        "\n",
        "final_prediction = ort_outs[0]\n",
        "\n",
        "final_prediction = torch.from_numpy(final_prediction)\n",
        "result = post_process(final_prediction, characters, {}, dict_list)\n",
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Available', 0.9877454042434692]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJkIkxUgoj-m"
      },
      "source": [
        "**ONNX output is matching with the actual model output**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hccQnDQorDc"
      },
      "source": [
        "## Convert to Tensorflow Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wk8OArP1oNTN"
      },
      "source": [
        "onnx_model = onnx.load('sequence_modeller.onnx')\n",
        "tf_rep = prepare(onnx_model)\n",
        "tf_rep.export_graph('sequence_modeller.pb')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaH6GstMo9sQ"
      },
      "source": [
        "**Conversion to Tensorflow Graph Succesful**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bt92wZISpCQ9"
      },
      "source": [
        "## TFLite Conversion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "Q5F59WAIozBT",
        "outputId": "d45a807b-bf3e-465e-f4bf-72e4091eb19f"
      },
      "source": [
        "loaded = tf.saved_model.load('sequence_modeller.pb')\n",
        "\n",
        "concrete_func = loaded.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
        "\n",
        "concrete_func.inputs[0].set_shape([1, 100, 512])\n",
        "converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tf_lite_model = converter.convert()\n",
        "open('sequence_modeller.tflite', 'wb').write(tf_lite_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ConverterError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[0;34m(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[1;32m    198\u001b[0m                                                  \u001b[0mdebug_info_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                                                  enable_mlir_converter)\n\u001b[0m\u001b[1;32m    200\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/wrap_toco.py\u001b[0m in \u001b[0;36mwrapped_toco_convert\u001b[0;34m(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[1;32m     37\u001b[0m       \u001b[0mdebug_info_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m       enable_mlir_converter)\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: input resource[0] expected type resource != float, the type of assignvariableop_resource_0[0]\n\tIn {{node AssignVariableOp}}",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mConverterError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-826feb3b2c42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_concrete_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconcrete_func\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtf_lite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sequence_modeller.tflite'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_lite_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m         \u001b[0mInvalid\u001b[0m \u001b[0mquantization\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m     \"\"\"\n\u001b[0;32m-> 1076\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTFLiteConverterV2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m     return super(TFLiteFrozenGraphConverterV2,\n\u001b[0;32m--> 900\u001b[0;31m                  self).convert(graph_def, input_tensors, output_tensors)\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, graph_def, input_tensors, output_tensors)\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0moutput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m         **converter_kwargs)\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     calibrate_and_quantize, flags = quant_mode.quantizer_flags(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_impl\u001b[0;34m(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m       \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m       \u001b[0mdebug_info_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug_info_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m       enable_mlir_converter=enable_mlir_converter)\n\u001b[0m\u001b[1;32m    575\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[0;34m(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[1;32m    200\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mConverterError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdistutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_executable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_toco_from_proto_bin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConverterError\u001b[0m: input resource[0] expected type resource != float, the type of assignvariableop_resource_0[0]\n\tIn {{node AssignVariableOp}}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5X5GYBopP5-"
      },
      "source": [
        "**This is the actual problem**"
      ]
    }
  ]
}